### 分布式和集群
	1.基本概念：分布式和集群是不一样的，分布式一定是集群，但是集群不一定是分布式。
	2.分布式是一个大系统拆分成多个小模块，而集群是实例的复制。

### 一致性Hash算法
	1.有多种形式：除留余数法，开放寻址法，直接寻址法，线性构造Hash算法。
	2.Hash算法在很多分布式集群产品中都有应用，比如分布式集群架构Redis、
	  Hadoop、ElasticSearch，Mysql分库分表，Nginx负载均衡等
	小结：一致性Hash算法主要的应用场景归纳起来两个：
			1.请求的负载均衡（比如nginx的ip_hash策略）。
			2.分布式存储
			
### 负载均衡（Hash算法应用）
	1.普通Hash算法存在的问题：当服务器数量发生了变化（扩容/缩容），之前所有的求模都需要重新计算。		
	  大量用户的请求会被路由到其他的目标服务器处理，用户在原来服务器中的会话都会丢失。
	2.一致性Hash算法：首先有一条直线，直线开头和结尾分别定为为1和2的32次⽅减1，这相当于一个地址，
	  对于这样一条线，弯过来构成一个圆环形成闭环，这样的圆环称为hash环。我们把服务器的ip或者主机名求
	  hash值然后对应到hash环上，那么针对客户端用户，也根据它的ip进行hash求值，对应到环上某个位置，然后
	  以顺时针获取最近的服务器，从而达到大部分的请求可以落到同一个服务器。避免了大量请求迁移。
	  问题分析：有可能会存在请求倾斜的问题的，由于服务器数量较少分布不均匀导致的。
	3.一致性Hash算法+虚拟节点：为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每个服务
	  节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。当客户端被路由到虚拟节点的时候其实是被
	  路由到该虚拟节点所对应的真实节点。
	  
### Nginx 配置一致性Hash负载均衡策略	  
	1.ngx_http_upstream_consistent_hash 模块是个负载均衡器，使用一个内部一致性hash算法来选择合适的后端节点。 
	  该模块可以根据配置参数采取不同的⽅式将请求均匀映射到后端机器，
	  consistent_hash $remote_addr：可以根据客户端ip映射
	  consistent_hash $request_uri：根据客户端请求的uri映射
	  consistent_hash $args：根据客户端携带的参数进⾏映
	  ngx_http_upstream_consistent_hash 模块是个第三方模块，需要我们下载安装后使用。 
	2.我们已经编译安装过nginx，此时进入当时nginx的源码目录，执行如下命令：
	  ./configure —add-module=/root/ngx_http_consistent_hash-master; make; make install;
	  在nginx.conf文件负载均衡配置中添加：consistent_hash $request_uri
	  
###	集群时钟同步问题(服务器时间)	
	1.时钟不同步导致的问题:时钟此处指服务器时间，如果集群中各个服务器时钟不一致势必导致一系列问题，集群是各个服
	  务器一起团队化作战，如果工作都不在一点上会导致数据混乱！
	2.时钟不同步的解决方法：
		（1）分布式集群中各个服务器节点都可以连接互联网（国家授时中心/时间服务器）。操作⽅式：
		     使用 ntpdate ⽹络时间同步命令：ntpdate -u ntp.api.bz 从某个时间服务器同步时间
			 Linux也有定时任务，crond，可以使用linux的定时任务，每隔10分钟执行一次ntpdate命令
		（2）分布式集群中某个服务器节点可以访问互联网或者所有节点都不能够访问互联网。
			 操作方法：选取集群中的某个服务器节点作为时间服务器（整个集群时间从这台服务
             器同步，如果这台服务器能够访问互联网，可以让这台服务器和网络时间保持同步，
			 如果不能就自动设置个时间。
			 
### 分布式ID解决方案
	1.UUID（通用唯一识别码）有可能产生重复，但是机率较低；
	2.独立数据库的自增ID，有性能瓶颈，当这个数据库实例挂掉后则无法提供分布式id服务。
	3.SnowFlake 雪花算法，生成的ID是个long型，那么在Java中long型是8个字节，算下来是64bit，
	  它的二进制形式由4个部分组成：符号位：1位，时间戳：41位，机器ID：10位，序列号：12位。
	  也就是说在同个时间（毫秒）同个机器一毫秒可以产生4099位唯一ID。
	4.借助Redis的Incr命令获取全局唯一ID，Redis的Incr命令将 key 中储存的数字值增1。如果key不存在，
	  那么key的值会先被初始化为0，然后再执行 INCR 操作。性能较高，但是依赖第三方中间件。
	  
### 分布式调度
	1.定时任务形式：每隔一定时间/特定某个时刻执行。
	2.什么是分布式调度：
		（1）运行在分布式集群环境下的调度任务：同个个定时任务程序部署多份，只应该有一个定时任务在执行。
			 并且当执行任务的服务宕机后其他服务器能继续执行。
		（2）分布式调度—>定时任务的分布式—>定时任务的拆分（即为把一个大的作业任务拆分为多个小的作
			 业任务，同时执行。	 
	3.定时任务与消息队列的区别：
		（1）共同点：异步处理(注册、下单)，应用解耦(将需要处理的事件放在表中，定时执行)，流量削峰（记录事件，不影响用户执行）。
		（2）本质不同：定时任务是属于时间驱动，消息队列属于事件驱动，执行的范围也是不同：定时任务是批量处理，消息队列是逐条处理。

### 定时任务的实现方式：	
	1.早期没有定时任务框架的时候，我们会使用JDK中的Timer机制和多线程机
	  制（Runnable+线程休眠）来实现定时或者间隔一段时间执行某段程序。
	2.Quartz任务调度框架，使用时间表达式（包括：秒、分、时、日、周、年）配置某一个任务什么时间去执行：
		（1）引入quartz的jar包，
		（2）创建作业任务调度器new StdSchedulerFactory().getScheduler()；
		（3）创建作业任务：JobBuilder.newJob(DemoJob implements Job的class).withIdentity("jobName","myJob")；jobBuilder.build()；
		（4）创建作业任务时间触发器：TriggerBuilder.newTrigger().withIdentity("triggerName","myTrigger").startNow()
			 .withSchedule(CronScheduleBuilder.cronSchedule("0/2 ** * * ?")).build();
		（5）使用调度器按照时间触发器执行这个作业任务scheduler.scheduleJob(job,trigger);scheduler.start();
	小结：回顾了下任务调度框架Quartz的大致用法，那么在分布式架构环境中使用Quartz已经不能更好
		  的满足我们需求，我们可以使用专业的分布式调度框架：Elastic-job。

### 分布式调度框架Elastic-Job
	1.基本介绍：Elastic-Job是当当网开源的分布式调度解决方案，基于Quartz二次开发的，由两个相互独立的项
	  目Elastic-Job-Lite和Elastic-Job-Cloud组成。我们要学习的是 Elastic-Job-Lite，它定位为轻量级去中心
	  化解决方案，使用Jar包的形式提供分布式任务的协调服务，而Elastic-Job-Cloud子项目需要结合Mesos以及
	  Docker在云环境下使用。
	2.主要功能构成：
		（1）分布式调度协调：可以根据分片策略避免部署在多个实例中的任务重复执行；
		（2）丰富的调度策略：基于成熟的定时任务作业框架Quartz cron表达式执行定时任务；
		（3）弹性扩容缩容 当集群中增加实例，它应当也能够被选举并执行任务；当集群减少个实例
			 时，它所执行的任务能被转移到别的实例来执行；
		（4）失效转移 某实例在任务执行失败后，会被转移到其他实例执行。
		（5）错过执行作业重触发 若因某种原因导致作业错过执行，自动记录错过的作业，并在上次作业
			 完成后自动触发。		
		（6）支持并行调度 支持任务分片，任务分片是指将一个任务分为多个小任务项在多个实例同时执⾏。
		（7）作业分片一致性 当任务被分片后，保证同一个分片在分布式环境中仅一个执行实例。

### Elastic-job-lite的使用
	1.Elastic-Job依赖于Zookeeper进行分布式协调，zookeeper的主要作用就是存储+通知，所以分布式调度中常常需要zookeeper进行协调。
	2.创建一个任务类并实现SimpleJob接口，重写其execute方法，该方法会执行具体任务和将分片信息传入该方法。
	3.配置注册中zookeeper，zookeeper协调调度，不能让任务重复执行，通过命名空间分类管理任务，对应到zookeeper的记录。
		ZookeeperConfiguration zookeeperConfiguration = new ZookeeperConfiguration("localhost:2181","data-archive-job");
		CoordinatorRegistryCenter coordinatorRegistryCenter = new ZookeeperRegistryCenter(zookeeperConfiguration);
		coordinatorRegistryCenter.init();
	4.配置任务：执行任务名称，执行时间
		JobCoreConfiguration jobCoreConfiguration = JobCoreConfiguration.newBuilder("archive-job","*/2 * * * * ?",1).build();
		SimpleJobConfiguration simpleJobConfiguration = new SimpleJobConfiguration(jobCoreConfiguration,BackupJob.class.getName());
	5.启动任务：
		new JobScheduler(coordinatorRegistryCenter,LiteJobConfiguration.newBuilder(simpleJobConfiguration).build()).init();	
		
### zookeeper工作说明
-	每个Elastic-Job的任务执行实例作为Zookeeper的客户端来操作ZooKeeper的znode；
-	多个实例同时创建/leader节点，/leader节点只能创建⼀个，后创建的会失败，创建成功的实例会被选为leader节点。
-	elestic-job会将任务信息传递给zookeeper,而zookeeper中包含leader(主节点)，servers（配置信息），instances（实例列表）,sharding(分片列表)。
	每一个拥有该任务的实例一旦启动，zookeeper会将该实例的信息通知leaer节点，leader节点会根据分片算法对该实例进行任务分片。
	当某一个节点挂掉后zookeeper也会通知leader节点，将该节点的任务分配给其他节点。
	
### Elastic-Job-Lite轻量级去中心化的特点	
	1.去中心化：没有调度中心分配，都是由每一个独立的实例子触发，主节点也是非固定的，节点与节点之间处于平等的关系。
	2.轻量级：不需要过多依赖第三方，只需要依赖zookeeper即可。只是一个java程序。
	
### 任务分片
	1.如果说只通过一个实例来执行一个大的任务，那会将所有的IO压力和计算压力都压在一个实例上。
	2.任务分片就是将一个大的task根据分片策略分成多个小的task，可以说是一种分流处理。
	3.在任务对象SimpleJob的执行方法中，我们可以拿到ShardingContext对象，可以根据此对象获取当前分片序号，
	  String shardingParameter = shardingContext.getShardingParameter(); 以此信息为依据执行任务。
	  
### 弹性扩容
	1.新增加一个运行实例，它会自动注册到注册中心，注册中心发现新的服务上线，注册中心会通知
	  ElasticJob 进行重新分片，那么总得分片项有多少，那么就可以搞多少个实例机器。
	小结：分片项也是个JOB配置，修改配置，重新分片，在下次定时运行之前会重新调用分片算法，那么
		  这个分片算法的结果就是：哪台机器运行哪个分片，这个结果存储到zk中的，主节点会把分片给分好
		  放到注册中心去，然后执行节点从注册中心获取信息(执行节点在定时任务开启的时候获取相应的分
		  行)。 如果所有的节点挂掉值剩下1个节点，所有分片都会指向剩下的1个节点，这也是ElasticJob的高可用。  
	
###  Session共享问题
-	 因为Http协议是无状态的协议。客户端和服务端在某次会话中产生的数据不会被保留下来，所以第二次请求服务
     端无法认识到你曾经来过，随着动态的内容更丰富，就需要有状态，出现了两种用于保持Http状态的技术，
     那就是Cookie和Session

### 解决Session一致性的方案
	1.Nginx的 IP_Hash 策略：同个客户端IP的请求都会被路由到同个目标服务器，也叫做会话粘滞。
	  可能带来的问题有服务器重启session丢失，存在单点负载高的问题。
	2.Session复制（不推荐）多个tomcat之间通过修改配置文件，达到Session之间的复制。
	  这种策略虽然不会产生session丢失也能适应各种负载均衡策略，但是且存在性能瓶颈，
	  比如session同步延迟，或者session过多，产生存储瓶颈。
	3.Session共享，Session集中存储。Session的本质就是缓存，那我们就把Session数据交给
	  专业的缓存中间件处理，比如redis。这种策略的扩展性强，适合各种负载策略，也不会产生session丢失。
	  
### Spring Session（Session共享策略）
	1.引入spring-boot-starter-data-redis和spring-session-data-redis两个依赖。主类上添加@EnableRedisHttpSession注解。
	2.Spring Session在请求到达Servlet之前做了一个过滤器处理，会从redis中获取对应的session信息，没有session信息则创建
	  一个RedisSession并放到redis当中。否则的话则从tomcat中。
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		
		